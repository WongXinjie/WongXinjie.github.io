title: 跳坑启示录
date: 2015-12-14 01:46:43
categories: 工作
tags:
- 总结
---

在近期的一个项目中，需要实现这样一个功能：冲HLS直播源中拉流到公司服务器，再构建m3u8文件同时对ts文件进行转码，通过公司的服务器再将m3u8和ts文件分发出去。简单来讲，就是先作为直播客户端， 将直播的HLS文件同步到服务器，然后通过公司的服务器对这些ts进行预加载以及多码率装码后重新构建m3u8文件，作为HLS直播的服务器，相当于直播转播的一个功能。  
最开始的时候这个功能是由公司的其他同事利用ffmpeg来实现的，但是在实际测试中发现效果不是很理想，首先是利用ffmpeg实现HLS直播转播时，播放时间长会出现卡顿和音画不同步的现象；还有一个问题就是程序难以控制，因为程序的实现实际上是用python的subprocess来调用linux shell命令来实现的，虽然suprocess模块提供了poll/terminate等函数来获取子进程的状态和杀死子进程，但作为一个面向企业用户的直播转播服务，这种实现显然不行。   

<!-- more -->
于是我就被分配来实现这个功能，讲原本ffmpeg实现的直播转播功能，用python实现一遍。一开始实现时没有怎么思考，一个模块是不断的请求更新m3u8文件，然后根据文件不断下载新的ts文件存储到本地指定目录，另外一个模块是根据下载完成的ts文件重新构建m3u8文件，同时有一个模块还要不断的轮询redis是否客户更新了直播流的状态，如果客户更新或停止删除了直播流，那么程序应该做相应的处理。同时考虑到，下载m3u8和ts文件这个程序可能比较耗时，所以应该独立起一个线程来下载和更新，而轮询和更新，嗯，估计也要新起一个线程来不断的更新m3u8文件。最终程序的实现：
一个m3u8downloader线程不断的请求更新m3u8，然后下载ts文件，再讲ts信息不断的push进task_queue里，再将下载的状态（停止或者出错）信息push到msg_queue，直到直播停止/出错/用户停止删除直播时才停止运行。

```python
while not kill_received:
    ...
```

一个hlsliveworker线程不断的从task_queue get ts文件的信息，append到一个deque队列中，然后构建m3u8文件，直到task_queue为空同时msg_queue不为空获知用户停止了直播才停止运行。
```python
while not kill_received  and (task_message or not msg_queue.emtpy()):
    ...
```

另为一个hlslivemanager的程序，跑以上的两个线程，同时不断的间隔轮询用户的直播更新信息，一旦发现用户更新了直播源或多码率选项，就杀死并重启连个线程，一旦用户停止了直播，则直接杀死两个线程。
这其实还能handle得了，但是hlslivemanager必须从redis那获取用户直播流信息，而redis直播流信息又是另外一个程序不断的轮询官网的数据库，将流信息变更不断塞到数据库。而这些状态信息不能以简单的利用json/msgpack简单的打包然后push到队列里。进行直播转播是服务器集群，我们需要确切地知道是哪部服务器在处理这个直播转播的任务。最终利用了redis的list和hash来实现流信息同步，以流的唯一编码push到队列，然后将以唯一编码作为key，流具体状态信息及处理状态信息作为values放在redis hash中。而记录直播的状态就有new/updated/processing/blocked/deleted五种状态，空闲的hlslivemanager拿到信息后根据这些状态再进行处理。而运行中的hlslivemanager中则要不断的轮询redis hash中流信息的变更，并将信息同步到redis hash中。
程序跑起来之后，一开始单测试时还是发现会有卡顿的现象，后来不断的俄调整m3u8构建程序的实现才有好转。但是出现一个问题就是程序跑起来占其中一个CPU的80%~100%，这个简直了，后来发现症结在几个while True类似循环中没有sleep，大部分时间都是满负荷空转。  
在经过简单的测试后，程序上线，一开始测试没问题，第二天测试，程序跑不起来了，也没有任务提示。后来拍错，发现自己测试时没有对更新状态进行测试，而用户恰好更新了直播源，而恰恰更新的那边存在一个bug，没有更新类属性，所以一更新便挂了。而我在测试的当晚接近两个小时，面对自己写的程序竟无从下手，两个线程都没什么问题，manager也没什么问题，可它就是跑不起来！

在付出一点代价之后，在同事的协助下，我对程序进行的重构。这次重构之前先仔细阅读了关于hls直播的rfc文档，发现其实之前的写法简直就是人为进行复杂化。
首先是，实现这个功能无须用多线程来实现。m3u8更新以及下载ts(<= 100KB)文件其实没想象中的那么耗时，而服务器这边更新一个m3u8文件是有条件的，即更新的间隔不能小于一个target_duration(>= 5s)时间间隔，而这个时间间隔其实时足以完成load m3u8文件==>下载ts文件==>预加载ts/构建m3u8/将转码任务分发出去/查看是否转码完成等任务的，即单线程是妥妥地可以完成这些工作的！
于是在重构中，将原本两个模块实现的，拆分成了四个模块，一个不断的load m3u8，然后将新的ts信息不断的yield出去，一个只做ts文件的下载任务，一个只实现m3u8文件的构建，另外一个就是统筹前面三个模块的handler，同时讲信息同步的状态修改为只有run/stop两种。之前程序的三个while True变成了一个while True和两个yield，程序的逻辑也变得清晰了许多：load m3u8 ==> download ts ==> update m3u8 ==> check user hls live info ==> load m3u8 ==>...

这个简单的任务，我花了三周才实现，其中包括一周的重构，要说教训，我想是有的。
1.想好要怎么做才去做，该读的文档要读还是要仔细读。
2.不是形式要并行的程序都要用线程/进程来实现并行，在写并行程序时想想真的必须真的只能以并发的形式实现么。
3.多线程不会是最优的选择。
4.最重要的，程序首先是给人读的，然后才是给机器运行的。一个逻辑清新的程序才是一个可以提交的程序。

